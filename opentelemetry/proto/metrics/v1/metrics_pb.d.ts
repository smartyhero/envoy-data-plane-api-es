// Copyright 2019, OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.10.0
// @generated from file opentelemetry/proto/metrics/v1/metrics.proto (package opentelemetry.proto.metrics.v1, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv2";
import type { Message } from "@bufbuild/protobuf";
import type { Resource } from "../../resource/v1/resource_pb";
import type { InstrumentationScope, KeyValue } from "../../common/v1/common_pb";

/**
 * Describes the file opentelemetry/proto/metrics/v1/metrics.proto.
 */
export declare const file_opentelemetry_proto_metrics_v1_metrics: GenFile;

/**
 * MetricsData represents the metrics data that can be stored in a persistent
 * storage, OR can be embedded by other protocols that transfer OTLP metrics
 * data but do not implement the OTLP protocol.
 *
 * MetricsData
 * └─── ResourceMetrics
 *   ├── Resource
 *   ├── SchemaURL
 *   └── ScopeMetrics
 *      ├── Scope
 *      ├── SchemaURL
 *      └── Metric
 *         ├── Name
 *         ├── Description
 *         ├── Unit
 *         └── data
 *            ├── Gauge
 *            ├── Sum
 *            ├── Histogram
 *            ├── ExponentialHistogram
 *            └── Summary
 *
 * The main difference between this message and collector protocol is that
 * in this message there will not be any "control" or "metadata" specific to
 * OTLP protocol.
 *
 * When new fields are added into this message, the OTLP request MUST be updated
 * as well.
 *
 * @generated from message opentelemetry.proto.metrics.v1.MetricsData
 */
export declare type MetricsData = Message<"opentelemetry.proto.metrics.v1.MetricsData"> & {
  /**
   * An array of ResourceMetrics.
   * For data coming from a single resource this array will typically contain
   * one element. Intermediary nodes that receive data from multiple origins
   * typically batch the data before forwarding further and in that case this
   * array will contain multiple elements.
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.ResourceMetrics resource_metrics = 1;
   */
  resourceMetrics: ResourceMetrics[];
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.MetricsData.
 * Use `create(MetricsDataSchema)` to create a new message.
 */
export declare const MetricsDataSchema: GenMessage<MetricsData>;

/**
 * A collection of ScopeMetrics from a Resource.
 *
 * @generated from message opentelemetry.proto.metrics.v1.ResourceMetrics
 */
export declare type ResourceMetrics = Message<"opentelemetry.proto.metrics.v1.ResourceMetrics"> & {
  /**
   * The resource for the metrics in this message.
   * If this field is not set then no resource info is known.
   *
   * @generated from field: opentelemetry.proto.resource.v1.Resource resource = 1;
   */
  resource?: Resource;

  /**
   * A list of metrics that originate from a resource.
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.ScopeMetrics scope_metrics = 2;
   */
  scopeMetrics: ScopeMetrics[];

  /**
   * The Schema URL, if known. This is the identifier of the Schema that the resource data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "resource" field. It does not apply
   * to the data in the "scope_metrics" field which have their own schema_url field.
   *
   * @generated from field: string schema_url = 3;
   */
  schemaUrl: string;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.ResourceMetrics.
 * Use `create(ResourceMetricsSchema)` to create a new message.
 */
export declare const ResourceMetricsSchema: GenMessage<ResourceMetrics>;

/**
 * A collection of Metrics produced by an Scope.
 *
 * @generated from message opentelemetry.proto.metrics.v1.ScopeMetrics
 */
export declare type ScopeMetrics = Message<"opentelemetry.proto.metrics.v1.ScopeMetrics"> & {
  /**
   * The instrumentation scope information for the metrics in this message.
   * Semantically when InstrumentationScope isn't set, it is equivalent with
   * an empty instrumentation scope name (unknown).
   *
   * @generated from field: opentelemetry.proto.common.v1.InstrumentationScope scope = 1;
   */
  scope?: InstrumentationScope;

  /**
   * A list of metrics that originate from an instrumentation library.
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.Metric metrics = 2;
   */
  metrics: Metric[];

  /**
   * The Schema URL, if known. This is the identifier of the Schema that the metric data
   * is recorded in. Notably, the last part of the URL path is the version number of the
   * schema: http[s]://server[:port]/path/<version>. To learn more about Schema URL see
   * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
   * This schema_url applies to the data in the "scope" field and all metrics in the
   * "metrics" field.
   *
   * @generated from field: string schema_url = 3;
   */
  schemaUrl: string;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.ScopeMetrics.
 * Use `create(ScopeMetricsSchema)` to create a new message.
 */
export declare const ScopeMetricsSchema: GenMessage<ScopeMetrics>;

/**
 * Defines a Metric which has one or more timeseries.  The following is a
 * brief summary of the Metric data model.  For more details, see:
 *
 *   https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md
 *
 * The data model and relation between entities is shown in the
 * diagram below. Here, "DataPoint" is the term used to refer to any
 * one of the specific data point value types, and "points" is the term used
 * to refer to any one of the lists of points contained in the Metric.
 *
 * - Metric is composed of a metadata and data.
 * - Metadata part contains a name, description, unit.
 * - Data is one of the possible types (Sum, Gauge, Histogram, Summary).
 * - DataPoint contains timestamps, attributes, and one of the possible value type
 *   fields.
 *
 *    Metric
 *  +------------+
 *  |name        |
 *  |description |
 *  |unit        |     +------------------------------------+
 *  |data        |---> |Gauge, Sum, Histogram, Summary, ... |
 *  +------------+     +------------------------------------+
 *
 *    Data [One of Gauge, Sum, Histogram, Summary, ...]
 *  +-----------+
 *  |...        |  // Metadata about the Data.
 *  |points     |--+
 *  +-----------+  |
 *                 |      +---------------------------+
 *                 |      |DataPoint 1                |
 *                 v      |+------+------+   +------+ |
 *              +-----+   ||label |label |...|label | |
 *              |  1  |-->||value1|value2|...|valueN| |
 *              +-----+   |+------+------+   +------+ |
 *              |  .  |   |+-----+                    |
 *              |  .  |   ||value|                    |
 *              |  .  |   |+-----+                    |
 *              |  .  |   +---------------------------+
 *              |  .  |                   .
 *              |  .  |                   .
 *              |  .  |                   .
 *              |  .  |   +---------------------------+
 *              |  .  |   |DataPoint M                |
 *              +-----+   |+------+------+   +------+ |
 *              |  M  |-->||label |label |...|label | |
 *              +-----+   ||value1|value2|...|valueN| |
 *                        |+------+------+   +------+ |
 *                        |+-----+                    |
 *                        ||value|                    |
 *                        |+-----+                    |
 *                        +---------------------------+
 *
 * Each distinct type of DataPoint represents the output of a specific
 * aggregation function, the result of applying the DataPoint's
 * associated function of to one or more measurements.
 *
 * All DataPoint types have three common fields:
 * - Attributes includes key-value pairs associated with the data point
 * - TimeUnixNano is required, set to the end time of the aggregation
 * - StartTimeUnixNano is optional, but strongly encouraged for DataPoints
 *   having an AggregationTemporality field, as discussed below.
 *
 * Both TimeUnixNano and StartTimeUnixNano values are expressed as
 * UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
 *
 * # TimeUnixNano
 *
 * This field is required, having consistent interpretation across
 * DataPoint types.  TimeUnixNano is the moment corresponding to when
 * the data point's aggregate value was captured.
 *
 * Data points with the 0 value for TimeUnixNano SHOULD be rejected
 * by consumers.
 *
 * # StartTimeUnixNano
 *
 * StartTimeUnixNano in general allows detecting when a sequence of
 * observations is unbroken.  This field indicates to consumers the
 * start time for points with cumulative and delta
 * AggregationTemporality, and it should be included whenever possible
 * to support correct rate calculation.  Although it may be omitted
 * when the start time is truly unknown, setting StartTimeUnixNano is
 * strongly encouraged.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Metric
 */
export declare type Metric = Message<"opentelemetry.proto.metrics.v1.Metric"> & {
  /**
   * The name of the metric.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * A description of the metric, which can be used in documentation.
   *
   * @generated from field: string description = 2;
   */
  description: string;

  /**
   * The unit in which the metric value is reported. Follows the format
   * described by https://unitsofmeasure.org/ucum.html.
   *
   * @generated from field: string unit = 3;
   */
  unit: string;

  /**
   * Data determines the aggregation type (if any) of the metric, what is the
   * reported value type for the data points, as well as the relatationship to
   * the time interval over which they are reported.
   *
   * @generated from oneof opentelemetry.proto.metrics.v1.Metric.data
   */
  data: {
    /**
     * @generated from field: opentelemetry.proto.metrics.v1.Gauge gauge = 5;
     */
    value: Gauge;
    case: "gauge";
  } | {
    /**
     * @generated from field: opentelemetry.proto.metrics.v1.Sum sum = 7;
     */
    value: Sum;
    case: "sum";
  } | {
    /**
     * @generated from field: opentelemetry.proto.metrics.v1.Histogram histogram = 9;
     */
    value: Histogram;
    case: "histogram";
  } | {
    /**
     * @generated from field: opentelemetry.proto.metrics.v1.ExponentialHistogram exponential_histogram = 10;
     */
    value: ExponentialHistogram;
    case: "exponentialHistogram";
  } | {
    /**
     * @generated from field: opentelemetry.proto.metrics.v1.Summary summary = 11;
     */
    value: Summary;
    case: "summary";
  } | { case: undefined; value?: undefined };

  /**
   * Additional metadata attributes that describe the metric. [Optional].
   * Attributes are non-identifying.
   * Consumers SHOULD NOT need to be aware of these attributes.
   * These attributes MAY be used to encode information allowing
   * for lossless roundtrip translation to / from another data model.
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue metadata = 12;
   */
  metadata: KeyValue[];
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Metric.
 * Use `create(MetricSchema)` to create a new message.
 */
export declare const MetricSchema: GenMessage<Metric>;

/**
 * Gauge represents the type of a scalar metric that always exports the
 * "current value" for every data point. It should be used for an "unknown"
 * aggregation.
 *
 * A Gauge does not support different aggregation temporalities. Given the
 * aggregation is unknown, points cannot be combined using the same
 * aggregation, regardless of aggregation temporalities. Therefore,
 * AggregationTemporality is not included. Consequently, this also means
 * "StartTimeUnixNano" is ignored for all data points.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Gauge
 */
export declare type Gauge = Message<"opentelemetry.proto.metrics.v1.Gauge"> & {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.NumberDataPoint data_points = 1;
   */
  dataPoints: NumberDataPoint[];
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Gauge.
 * Use `create(GaugeSchema)` to create a new message.
 */
export declare const GaugeSchema: GenMessage<Gauge>;

/**
 * Sum represents the type of a scalar metric that is calculated as a sum of all
 * reported measurements over a time interval.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Sum
 */
export declare type Sum = Message<"opentelemetry.proto.metrics.v1.Sum"> & {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.NumberDataPoint data_points = 1;
   */
  dataPoints: NumberDataPoint[];

  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   *
   * @generated from field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;
   */
  aggregationTemporality: AggregationTemporality;

  /**
   * Represents whether the sum is monotonic.
   *
   * @generated from field: bool is_monotonic = 3;
   */
  isMonotonic: boolean;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Sum.
 * Use `create(SumSchema)` to create a new message.
 */
export declare const SumSchema: GenMessage<Sum>;

/**
 * Histogram represents the type of a metric that is calculated by aggregating
 * as a Histogram of all reported measurements over a time interval.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Histogram
 */
export declare type Histogram = Message<"opentelemetry.proto.metrics.v1.Histogram"> & {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.HistogramDataPoint data_points = 1;
   */
  dataPoints: HistogramDataPoint[];

  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   *
   * @generated from field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;
   */
  aggregationTemporality: AggregationTemporality;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Histogram.
 * Use `create(HistogramSchema)` to create a new message.
 */
export declare const HistogramSchema: GenMessage<Histogram>;

/**
 * ExponentialHistogram represents the type of a metric that is calculated by aggregating
 * as a ExponentialHistogram of all reported double measurements over a time interval.
 *
 * @generated from message opentelemetry.proto.metrics.v1.ExponentialHistogram
 */
export declare type ExponentialHistogram = Message<"opentelemetry.proto.metrics.v1.ExponentialHistogram"> & {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint data_points = 1;
   */
  dataPoints: ExponentialHistogramDataPoint[];

  /**
   * aggregation_temporality describes if the aggregator reports delta changes
   * since last report time, or cumulative changes since a fixed start time.
   *
   * @generated from field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;
   */
  aggregationTemporality: AggregationTemporality;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.ExponentialHistogram.
 * Use `create(ExponentialHistogramSchema)` to create a new message.
 */
export declare const ExponentialHistogramSchema: GenMessage<ExponentialHistogram>;

/**
 * Summary metric data are used to convey quantile summaries,
 * a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)
 * and OpenMetrics (see: https://github.com/prometheus/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)
 * data type. These data points cannot always be merged in a meaningful way.
 * While they can be useful in some applications, histogram data points are
 * recommended for new applications.
 * Summary metrics do not have an aggregation temporality field. This is
 * because the count and sum fields of a SummaryDataPoint are assumed to be
 * cumulative values.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Summary
 */
export declare type Summary = Message<"opentelemetry.proto.metrics.v1.Summary"> & {
  /**
   * The time series data points.
   * Note: Multiple time series may be included (same timestamp, different attributes).
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.SummaryDataPoint data_points = 1;
   */
  dataPoints: SummaryDataPoint[];
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Summary.
 * Use `create(SummarySchema)` to create a new message.
 */
export declare const SummarySchema: GenMessage<Summary>;

/**
 * NumberDataPoint is a single data point in a timeseries that describes the
 * time-varying scalar value of a metric.
 *
 * @generated from message opentelemetry.proto.metrics.v1.NumberDataPoint
 */
export declare type NumberDataPoint = Message<"opentelemetry.proto.metrics.v1.NumberDataPoint"> & {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 7;
   */
  attributes: KeyValue[];

  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 start_time_unix_nano = 2;
   */
  startTimeUnixNano: bigint;

  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 time_unix_nano = 3;
   */
  timeUnixNano: bigint;

  /**
   * The value itself.  A point is considered invalid when one of the recognized
   * value fields is not present inside this oneof.
   *
   * @generated from oneof opentelemetry.proto.metrics.v1.NumberDataPoint.value
   */
  value: {
    /**
     * @generated from field: double as_double = 4;
     */
    value: number;
    case: "asDouble";
  } | {
    /**
     * @generated from field: sfixed64 as_int = 6;
     */
    value: bigint;
    case: "asInt";
  } | { case: undefined; value?: undefined };

  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 5;
   */
  exemplars: Exemplar[];

  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   *
   * @generated from field: uint32 flags = 8;
   */
  flags: number;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.NumberDataPoint.
 * Use `create(NumberDataPointSchema)` to create a new message.
 */
export declare const NumberDataPointSchema: GenMessage<NumberDataPoint>;

/**
 * HistogramDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a Histogram. A Histogram contains summary statistics
 * for a population of values, it may optionally contain the distribution of
 * those values across a set of buckets.
 *
 * If the histogram contains the distribution of values, then both
 * "explicit_bounds" and "bucket counts" fields must be defined.
 * If the histogram does not contain the distribution of values, then both
 * "explicit_bounds" and "bucket_counts" must be omitted and only "count" and
 * "sum" are known.
 *
 * @generated from message opentelemetry.proto.metrics.v1.HistogramDataPoint
 */
export declare type HistogramDataPoint = Message<"opentelemetry.proto.metrics.v1.HistogramDataPoint"> & {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 9;
   */
  attributes: KeyValue[];

  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 start_time_unix_nano = 2;
   */
  startTimeUnixNano: bigint;

  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 time_unix_nano = 3;
   */
  timeUnixNano: bigint;

  /**
   * count is the number of values in the population. Must be non-negative. This
   * value must be equal to the sum of the "count" fields in buckets if a
   * histogram is provided.
   *
   * @generated from field: fixed64 count = 4;
   */
  count: bigint;

  /**
   * sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
   *
   * @generated from field: optional double sum = 5;
   */
  sum?: number;

  /**
   * bucket_counts is an optional field contains the count values of histogram
   * for each bucket.
   *
   * The sum of the bucket_counts must equal the value in the count field.
   *
   * The number of elements in bucket_counts array must be by one greater than
   * the number of elements in explicit_bounds array. The exception to this rule
   * is when the length of bucket_counts is 0, then the length of explicit_bounds
   * must also be 0.
   *
   * @generated from field: repeated fixed64 bucket_counts = 6;
   */
  bucketCounts: bigint[];

  /**
   * explicit_bounds specifies buckets with explicitly defined bounds for values.
   *
   * The boundaries for bucket at index i are:
   *
   * (-infinity, explicit_bounds[i]] for i == 0
   * (explicit_bounds[i-1], explicit_bounds[i]] for 0 < i < size(explicit_bounds)
   * (explicit_bounds[i-1], +infinity) for i == size(explicit_bounds)
   *
   * The values in the explicit_bounds array must be strictly increasing.
   *
   * Histogram buckets are inclusive of their upper boundary, except the last
   * bucket where the boundary is at infinity. This format is intentionally
   * compatible with the OpenMetrics histogram definition.
   *
   * If bucket_counts length is 0 then explicit_bounds length must also be 0,
   * otherwise the data point is invalid.
   *
   * @generated from field: repeated double explicit_bounds = 7;
   */
  explicitBounds: number[];

  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 8;
   */
  exemplars: Exemplar[];

  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   *
   * @generated from field: uint32 flags = 10;
   */
  flags: number;

  /**
   * min is the minimum value over (start_time, end_time].
   *
   * @generated from field: optional double min = 11;
   */
  min?: number;

  /**
   * max is the maximum value over (start_time, end_time].
   *
   * @generated from field: optional double max = 12;
   */
  max?: number;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.HistogramDataPoint.
 * Use `create(HistogramDataPointSchema)` to create a new message.
 */
export declare const HistogramDataPointSchema: GenMessage<HistogramDataPoint>;

/**
 * ExponentialHistogramDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a ExponentialHistogram of double values. A ExponentialHistogram contains
 * summary statistics for a population of values, it may optionally contain the
 * distribution of those values across a set of buckets.
 *
 *
 * @generated from message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint
 */
export declare type ExponentialHistogramDataPoint = Message<"opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint"> & {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 1;
   */
  attributes: KeyValue[];

  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 start_time_unix_nano = 2;
   */
  startTimeUnixNano: bigint;

  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 time_unix_nano = 3;
   */
  timeUnixNano: bigint;

  /**
   * The number of values in the population. Must be
   * non-negative. This value must be equal to the sum of the "bucket_counts"
   * values in the positive and negative Buckets plus the "zero_count" field.
   *
   * @generated from field: fixed64 count = 4;
   */
  count: bigint;

  /**
   * The sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#histogram
   *
   * @generated from field: optional double sum = 5;
   */
  sum?: number;

  /**
   * scale describes the resolution of the histogram.  Boundaries are
   * located at powers of the base, where:
   *
   *   base = (2^(2^-scale))
   *
   * The histogram bucket identified by `index`, a signed integer,
   * contains values that are greater than (base^index) and
   * less than or equal to (base^(index+1)).
   *
   * The positive and negative ranges of the histogram are expressed
   * separately.  Negative values are mapped by their absolute value
   * into the negative range using the same scale as the positive range.
   *
   * scale is not restricted by the protocol, as the permissible
   * values depend on the range of the data.
   *
   * @generated from field: sint32 scale = 6;
   */
  scale: number;

  /**
   * The count of values that are either exactly zero or
   * within the region considered zero by the instrumentation at the
   * tolerated degree of precision.  This bucket stores values that
   * cannot be expressed using the standard exponential formula as
   * well as values that have been rounded to zero.
   *
   * Implementations MAY consider the zero bucket to have probability
   * mass equal to (zero_count / count).
   *
   * @generated from field: fixed64 zero_count = 7;
   */
  zeroCount: bigint;

  /**
   * positive carries the positive range of exponential bucket counts.
   *
   * @generated from field: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets positive = 8;
   */
  positive?: ExponentialHistogramDataPoint_Buckets;

  /**
   * negative carries the negative range of exponential bucket counts.
   *
   * @generated from field: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets negative = 9;
   */
  negative?: ExponentialHistogramDataPoint_Buckets;

  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   *
   * @generated from field: uint32 flags = 10;
   */
  flags: number;

  /**
   * (Optional) List of exemplars collected from
   * measurements that were used to form the data point
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 11;
   */
  exemplars: Exemplar[];

  /**
   * The minimum value over (start_time, end_time].
   *
   * @generated from field: optional double min = 12;
   */
  min?: number;

  /**
   * The maximum value over (start_time, end_time].
   *
   * @generated from field: optional double max = 13;
   */
  max?: number;

  /**
   * ZeroThreshold may be optionally set to convey the width of the zero
   * region. Where the zero region is defined as the closed interval
   * [-ZeroThreshold, ZeroThreshold].
   * When ZeroThreshold is 0, zero count bucket stores values that cannot be
   * expressed using the standard exponential formula as well as values that
   * have been rounded to zero.
   *
   * @generated from field: double zero_threshold = 14;
   */
  zeroThreshold: number;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.
 * Use `create(ExponentialHistogramDataPointSchema)` to create a new message.
 */
export declare const ExponentialHistogramDataPointSchema: GenMessage<ExponentialHistogramDataPoint>;

/**
 * Buckets are a set of bucket counts, encoded in a contiguous array
 * of counts.
 *
 * @generated from message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets
 */
export declare type ExponentialHistogramDataPoint_Buckets = Message<"opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets"> & {
  /**
   * The bucket index of the first entry in the bucket_counts array.
   *
   * Note: This uses a varint encoding as a simple form of compression.
   *
   * @generated from field: sint32 offset = 1;
   */
  offset: number;

  /**
   * An array of count values, where bucket_counts[i] carries
   * the count of the bucket at index (offset+i). bucket_counts[i] is the count
   * of values greater than base^(offset+i) and less than or equal to
   * base^(offset+i+1).
   *
   * Note: By contrast, the explicit HistogramDataPoint uses
   * fixed64.  This field is expected to have many buckets,
   * especially zeros, so uint64 has been selected to ensure
   * varint encoding.
   *
   * @generated from field: repeated uint64 bucket_counts = 2;
   */
  bucketCounts: bigint[];
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets.
 * Use `create(ExponentialHistogramDataPoint_BucketsSchema)` to create a new message.
 */
export declare const ExponentialHistogramDataPoint_BucketsSchema: GenMessage<ExponentialHistogramDataPoint_Buckets>;

/**
 * SummaryDataPoint is a single data point in a timeseries that describes the
 * time-varying values of a Summary metric. The count and sum fields represent
 * cumulative values.
 *
 * @generated from message opentelemetry.proto.metrics.v1.SummaryDataPoint
 */
export declare type SummaryDataPoint = Message<"opentelemetry.proto.metrics.v1.SummaryDataPoint"> & {
  /**
   * The set of key/value pairs that uniquely identify the timeseries from
   * where this point belongs. The list may be empty (may contain 0 elements).
   * Attribute keys MUST be unique (it is not allowed to have more than one
   * attribute with the same key).
   * The behavior of software that receives duplicated keys can be unpredictable.
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 7;
   */
  attributes: KeyValue[];

  /**
   * StartTimeUnixNano is optional but strongly encouraged, see the
   * the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 start_time_unix_nano = 2;
   */
  startTimeUnixNano: bigint;

  /**
   * TimeUnixNano is required, see the detailed comments above Metric.
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 time_unix_nano = 3;
   */
  timeUnixNano: bigint;

  /**
   * count is the number of values in the population. Must be non-negative.
   *
   * @generated from field: fixed64 count = 4;
   */
  count: bigint;

  /**
   * sum of the values in the population. If count is zero then this field
   * must be zero.
   *
   * Note: Sum should only be filled out when measuring non-negative discrete
   * events, and is assumed to be monotonic over the values of these events.
   * Negative events *can* be recorded, but sum should not be filled out when
   * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
   * see: https://github.com/prometheus/OpenMetrics/blob/v1.0.0/specification/OpenMetrics.md#summary
   *
   * @generated from field: double sum = 5;
   */
  sum: number;

  /**
   * (Optional) list of values at different quantiles of the distribution calculated
   * from the current snapshot. The quantiles must be strictly increasing.
   *
   * @generated from field: repeated opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile quantile_values = 6;
   */
  quantileValues: SummaryDataPoint_ValueAtQuantile[];

  /**
   * Flags that apply to this specific data point.  See DataPointFlags
   * for the available flags and their meaning.
   *
   * @generated from field: uint32 flags = 8;
   */
  flags: number;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.SummaryDataPoint.
 * Use `create(SummaryDataPointSchema)` to create a new message.
 */
export declare const SummaryDataPointSchema: GenMessage<SummaryDataPoint>;

/**
 * Represents the value at a given quantile of a distribution.
 *
 * To record Min and Max values following conventions are used:
 * - The 1.0 quantile is equivalent to the maximum value observed.
 * - The 0.0 quantile is equivalent to the minimum value observed.
 *
 * See the following issue for more context:
 * https://github.com/open-telemetry/opentelemetry-proto/issues/125
 *
 * @generated from message opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile
 */
export declare type SummaryDataPoint_ValueAtQuantile = Message<"opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile"> & {
  /**
   * The quantile of a distribution. Must be in the interval
   * [0.0, 1.0].
   *
   * @generated from field: double quantile = 1;
   */
  quantile: number;

  /**
   * The value at the given quantile of a distribution.
   *
   * Quantile values must NOT be negative.
   *
   * @generated from field: double value = 2;
   */
  value: number;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile.
 * Use `create(SummaryDataPoint_ValueAtQuantileSchema)` to create a new message.
 */
export declare const SummaryDataPoint_ValueAtQuantileSchema: GenMessage<SummaryDataPoint_ValueAtQuantile>;

/**
 * A representation of an exemplar, which is a sample input measurement.
 * Exemplars also hold information about the environment when the measurement
 * was recorded, for example the span and trace ID of the active span when the
 * exemplar was recorded.
 *
 * @generated from message opentelemetry.proto.metrics.v1.Exemplar
 */
export declare type Exemplar = Message<"opentelemetry.proto.metrics.v1.Exemplar"> & {
  /**
   * The set of key/value pairs that were filtered out by the aggregator, but
   * recorded alongside the original measurement. Only key/value pairs that were
   * filtered out by the aggregator should be included
   *
   * @generated from field: repeated opentelemetry.proto.common.v1.KeyValue filtered_attributes = 7;
   */
  filteredAttributes: KeyValue[];

  /**
   * time_unix_nano is the exact time when this exemplar was recorded
   *
   * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
   * 1970.
   *
   * @generated from field: fixed64 time_unix_nano = 2;
   */
  timeUnixNano: bigint;

  /**
   * The value of the measurement that was recorded. An exemplar is
   * considered invalid when one of the recognized value fields is not present
   * inside this oneof.
   *
   * @generated from oneof opentelemetry.proto.metrics.v1.Exemplar.value
   */
  value: {
    /**
     * @generated from field: double as_double = 3;
     */
    value: number;
    case: "asDouble";
  } | {
    /**
     * @generated from field: sfixed64 as_int = 6;
     */
    value: bigint;
    case: "asInt";
  } | { case: undefined; value?: undefined };

  /**
   * (Optional) Span ID of the exemplar trace.
   * span_id may be missing if the measurement is not recorded inside a trace
   * or if the trace is not sampled.
   *
   * @generated from field: bytes span_id = 4;
   */
  spanId: Uint8Array;

  /**
   * (Optional) Trace ID of the exemplar trace.
   * trace_id may be missing if the measurement is not recorded inside a trace
   * or if the trace is not sampled.
   *
   * @generated from field: bytes trace_id = 5;
   */
  traceId: Uint8Array;
};

/**
 * Describes the message opentelemetry.proto.metrics.v1.Exemplar.
 * Use `create(ExemplarSchema)` to create a new message.
 */
export declare const ExemplarSchema: GenMessage<Exemplar>;

/**
 * AggregationTemporality defines how a metric aggregator reports aggregated
 * values. It describes how those values relate to the time interval over
 * which they are aggregated.
 *
 * @generated from enum opentelemetry.proto.metrics.v1.AggregationTemporality
 */
export enum AggregationTemporality {
  /**
   * UNSPECIFIED is the default AggregationTemporality, it MUST not be used.
   *
   * @generated from enum value: AGGREGATION_TEMPORALITY_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * DELTA is an AggregationTemporality for a metric aggregator which reports
   * changes since last report time. Successive metrics contain aggregation of
   * values from continuous and non-overlapping intervals.
   *
   * The values for a DELTA metric are based only on the time interval
   * associated with one measurement cycle. There is no dependency on
   * previous measurements like is the case for CUMULATIVE metrics.
   *
   * For example, consider a system measuring the number of requests that
   * it receives and reports the sum of these requests every second as a
   * DELTA metric:
   *
   *   1. The system starts receiving at time=t_0.
   *   2. A request is received, the system measures 1 request.
   *   3. A request is received, the system measures 1 request.
   *   4. A request is received, the system measures 1 request.
   *   5. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+1 with a value of 3.
   *   6. A request is received, the system measures 1 request.
   *   7. A request is received, the system measures 1 request.
   *   8. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0+1 to
   *      t_0+2 with a value of 2.
   *
   * @generated from enum value: AGGREGATION_TEMPORALITY_DELTA = 1;
   */
  DELTA = 1,

  /**
   * CUMULATIVE is an AggregationTemporality for a metric aggregator which
   * reports changes since a fixed start time. This means that current values
   * of a CUMULATIVE metric depend on all previous measurements since the
   * start time. Because of this, the sender is required to retain this state
   * in some form. If this state is lost or invalidated, the CUMULATIVE metric
   * values MUST be reset and a new fixed start time following the last
   * reported measurement time sent MUST be used.
   *
   * For example, consider a system measuring the number of requests that
   * it receives and reports the sum of these requests every second as a
   * CUMULATIVE metric:
   *
   *   1. The system starts receiving at time=t_0.
   *   2. A request is received, the system measures 1 request.
   *   3. A request is received, the system measures 1 request.
   *   4. A request is received, the system measures 1 request.
   *   5. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+1 with a value of 3.
   *   6. A request is received, the system measures 1 request.
   *   7. A request is received, the system measures 1 request.
   *   8. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_0 to
   *      t_0+2 with a value of 5.
   *   9. The system experiences a fault and loses state.
   *   10. The system recovers and resumes receiving at time=t_1.
   *   11. A request is received, the system measures 1 request.
   *   12. The 1 second collection cycle ends. A metric is exported for the
   *      number of requests received over the interval of time t_1 to
   *      t_0+1 with a value of 1.
   *
   * Note: Even though, when reporting changes since last report time, using
   * CUMULATIVE is valid, it is not recommended. This may cause problems for
   * systems that do not use start_time to determine when the aggregation
   * value was reset (e.g. Prometheus).
   *
   * @generated from enum value: AGGREGATION_TEMPORALITY_CUMULATIVE = 2;
   */
  CUMULATIVE = 2,
}

/**
 * Describes the enum opentelemetry.proto.metrics.v1.AggregationTemporality.
 */
export declare const AggregationTemporalitySchema: GenEnum<AggregationTemporality>;

/**
 * DataPointFlags is defined as a protobuf 'uint32' type and is to be used as a
 * bit-field representing 32 distinct boolean flags.  Each flag defined in this
 * enum is a bit-mask.  To test the presence of a single flag in the flags of
 * a data point, for example, use an expression like:
 *
 *   (point.flags & DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK) == DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK
 *
 *
 * @generated from enum opentelemetry.proto.metrics.v1.DataPointFlags
 */
export enum DataPointFlags {
  /**
   * The zero value for the enum. Should not be used for comparisons.
   * Instead use bitwise "and" with the appropriate mask as shown above.
   *
   * @generated from enum value: DATA_POINT_FLAGS_DO_NOT_USE = 0;
   */
  DO_NOT_USE = 0,

  /**
   * This DataPoint is valid but has no recorded value.  This value
   * SHOULD be used to reflect explicitly missing data in a series, as
   * for an equivalent to the Prometheus "staleness marker".
   *
   * @generated from enum value: DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK = 1;
   */
  NO_RECORDED_VALUE_MASK = 1,
}

/**
 * Describes the enum opentelemetry.proto.metrics.v1.DataPointFlags.
 */
export declare const DataPointFlagsSchema: GenEnum<DataPointFlags>;

